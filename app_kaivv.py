import os
from flask import request, Flask, render_template, redirect, url_for
from InferenceNLP import *
from inference_AUDIO import *
import torch


def baak(audio_result, result_sent, result_do, script_made_up = None):   # ë”•ì…”ë„ˆë¦¬ ì¶œë ¥ê°’ì„ (ìƒëŒ€ì )ì˜ˆìœ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥
    scripts = []
    script = ""
    if script_made_up:
        output = script_made_up
    else:
        output = {}
        for idx in range(len(audio_result)+1):
            if idx == 0:
                output[0] = {'deepfake' : "...", 'msg' : [], 'fraud' : []}  # ì²˜ìŒ 0~2ì´ˆëŠ” ì¼ë‹¨ ì •ìƒìŒì„±ì´ë¼ê³  í•œë‹¤...
            elif idx != len(audio_result):
                output[idx*2] = {'deepfake' : f"ìœ„ì¡°ìŒì„±({torch.sigmoid(torch.tensor(audio_result[idx][0][1]))*100:.1f}%)ğŸš¨" if audio_result[idx][0][0] < audio_result[idx][0][1] else f"ì •ìƒìŒì„±({torch.sigmoid(torch.tensor(audio_result[idx][0][0]))*100:.1f}%)ğŸ‘Œ", 'msg' : [], 'fraud' : []}
            else:
                output[idx*2] = {'deepfake' :output[(idx-1)*2]['deepfake'], 'msg' : [], 'fraud' : []} 
                # ë§ˆì§€ë§‰ì€ ìš°ë¦¬... 2ì´ˆë¯¸ë§Œ ë²„ë ¸ê¸°ë•Œë¬¸ì— ìì—°ì–´ë‘ ì§ì´ ì•ˆë§ì„ ìˆ˜ê°€ ìˆë‹¤. ê·¸ë˜ì„œ ê·¸ëƒ¥ ë°”ë¡œ ì „ íƒ€ì„ìŠ¤íƒ­ ê°’(idx-1)ì„ ë„ìš´ë‹¤
        for sent in result_sent:
            eos = sent['start_at'] + sent['duration']
            index = (eos//2000)*2
            output[index]['msg'].append(sent['msg'])
            output[index]['fraud'].append(f"fraud ({sent['phishing proba']*100:.1f}%)" if sent['normal proba'] < sent["phishing proba"] else f'normal ({sent["normal proba"]*100:.1f}%)') 

    for idx in output:
        script = "{timestep}\n{deepfake}\n{sents}".format(
            timestep = "ğŸ¤”íƒì§€ì¤‘ : " + str(idx) + "~" + str(idx+2) + "ì´ˆ",
            deepfake = output[idx]['deepfake'],
            sents = '\n'.join([i[1]+'\n'+i[0] for i in list(zip(output[idx]['msg'], output[idx]['fraud']))])
            )
        scripts.append(script)
    scripts.append("ğŸ¤” í†µí™” ì „ì²´ ë‚´ìš© \në¶„ì„ ê²°ê³¼\n : {}".format(
        f"ì‚¬ê¸° í†µí™” ê°€ëŠ¥ì„±\n\" ë†’ìŒ \" ({result_doc['phishing proba']*100:.1f})" if result_doc['phishing proba'] > result_doc['normal proba'] else f"ì •ìƒ í†µí™” ê°€ëŠ¥ì„±\n \" ë†’ìŒ \"({result_doc['normal proba']*100:.1f})"
    ))
    return scripts
####################################################################################################################################################################################

app = Flask(__name__, static_url_path= '/static')





UPLOAD_FOLDER = os.path.join(os.getcwd(), 'static', 'audio')
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
@app.route("/")
def first_page():
    return render_template('first_page.html')


@app.route("/upload", methods=["POST"])
def upload():
    file = request.files['file']

    if file:
        file.save(os.path.join(app.config['UPLOAD_FOLDER'], file.filename))
        print('ifë¬¸ ì…ì¥')
        global result_doc, result_sent, audio_result, scripts, audio_file

        audio_file = app.config['UPLOAD_FOLDER']+'/'+file.filename
        result_sent, result_doc = inlp.run(audio_file)
        wavs = preprocess_audio(audio_file)
        audio_result = []
        for wav in wavs:
            mels, audio_value_sixths, audio_value_lasts = crop_to_data(wav, HUBERT)
            logit = mm_model(mels.unsqueeze(0).to(device), audio_value_lasts.to(device)).detach().cpu().numpy() # audio_value_sixths, # in shape of (1, 2)
            prediction = np.argmax(logit, axis=1)[0] # ë¼ë²¨ì„ ë±‰ì„ê±°ë©´ prediction, ë¡œì§“ì„ ë±‰ì„ê±°ë©´ logit
            audio_result.append(logit) # ë¼ë²¨ì„ ë±‰ì„ê±°ë©´ prediction, ë¡œì§“ì„ ë±‰ì„ê±°ë©´ logit
            
        scripts = baak(audio_result, result_sent, result_doc)
        
        return redirect(url_for('main_page'))
    else:
        return redirect(url_for('main_page'))
@app.route("/main")
def main_page():
    return render_template('main_page.html')


@app.route("/result")
def result_page():
    return render_template('result.html', scripts=scripts, audio_file = audio_file)

@app.route("/phone")
def phone_page():
    return render_template('phone_templates.html')

# @app.route("/test")
# def test_page():
#     return render_template('test.html')


if __name__ == "__main__":
    print('ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ')
    device = "cuda:0" if torch.cuda.is_available() else 'cpu'

    image_model_path = '/home/alpaco/mel_spec_approach/khrdatatest/mk1_khrdatatest_lr0001_12.pt'
    audio_model_path = '/home/alpaco/KHR/MM_whole/checkpoints/new_my_audio_classifier_last_088_88.pt'
    # mm_model = MultiModal_mk1(image_model_path, audio_model_path).to(device)
    final_model_class = MultiModal_mk1
    final_checkpoint_path = '/home/alpaco/KHR/MM_whole/mm_checkpoints/mm_focal_4.pt'
    mm_model = load_torch_model(final_model_class, final_checkpoint_path, image_model_path=image_model_path, audio_model_path=audio_model_path).to(device)
    print('ë©€í‹°ëª¨ë‹¬ ë¡œë”© ì™„ë£Œ')
    mm_model.eval()
    HUBERT = load_hubert()
    print('íœ´ë²„íŠ¸ ë¡œë”© ì™„ë£Œ')

    inlp = InferenceNLP(
        sentclf_id = '/home/alpaco/csy/1005_sent_clf_with_clean',
        docclf_id = '/home/alpaco/csy/polyglot_for_document_clf_0926'
    )
    print('nlpëª¨ë¸ ë¡œë”© ì™„ë£Œ')    
    app.run(debug=False)